{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advised-inflation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bottom-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'HandGestureRecognitionNeuralNetwork/dataset/'\n",
    "#path = path + 'left/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "blank-grounds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 134 images belonging to 4 classes.\n",
      "Found 22 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(shear_range=0.2, zoom_range=0.4, height_shift_range=20 , validation_split = 0.15, horizontal_flip = True)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(path, target_size=(256, 256),\n",
    "    class_mode = 'categorical', shuffle=True, batch_size = 4, subset = 'training')\n",
    "\n",
    "\n",
    "val_generator = datagen.flow_from_directory(path, class_mode = 'categorical', subset = 'validation', shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "unlikely-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = next(train_generator)\n",
    "INPUT_SHAPE = k[0].shape\n",
    "label_shape = k[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "opponent-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_generator, output_signature = (\n",
    "                tf.TensorSpec(shape = INPUT_SHAPE, dtype = tf.float32),\n",
    "                tf.TensorSpec(shape = label_shape, dtype = tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "automated-cloud",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(4, 256, 256, 3), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(4, 4), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "flush-immune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "for k in train_dataset.take(1):\n",
    "    print(k[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "distinguished-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "combined-gamma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 254, 254, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 125, 125, 32)      18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                1968144   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 1,988,468\n",
      "Trainable params: 1,988,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "act = tf.nn.leaky_relu\n",
    "model = Sequential([\n",
    "    Conv2D(64, (3,3), activation = act, input_shape = (256, 256, 3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(32, (3,3), activation = act),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(16, activation = act),\n",
    "    Dense(4, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics =['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "successful-sarah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "34/34 [==============================] - 9s 268ms/step - loss: 4.1582 - accuracy: 0.7985 - val_loss: 2.6838 - val_accuracy: 0.8636\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 8s 224ms/step - loss: 1.7702 - accuracy: 0.8582 - val_loss: 2.4735 - val_accuracy: 0.8636\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 8s 231ms/step - loss: 1.8531 - accuracy: 0.8731 - val_loss: 4.0332 - val_accuracy: 0.7727\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 8s 235ms/step - loss: 2.8502 - accuracy: 0.8955 - val_loss: 3.9201 - val_accuracy: 0.7727\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 2.6164 - accuracy: 0.8209 - val_loss: 5.4931 - val_accuracy: 0.7727\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 8s 225ms/step - loss: 2.3640 - accuracy: 0.8433 - val_loss: 1.6021 - val_accuracy: 0.9091\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 8s 223ms/step - loss: 2.5725 - accuracy: 0.8433 - val_loss: 3.3438 - val_accuracy: 0.8636\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 1.0656 - accuracy: 0.9179 - val_loss: 0.7214 - val_accuracy: 0.9545\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 8s 228ms/step - loss: 2.1076 - accuracy: 0.8582 - val_loss: 0.2887 - val_accuracy: 0.9545\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 8s 225ms/step - loss: 2.4355 - accuracy: 0.8433 - val_loss: 1.4258 - val_accuracy: 0.8636\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 3.2240 - accuracy: 0.8433 - val_loss: 3.4797 - val_accuracy: 0.9091\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 8s 230ms/step - loss: 2.7781 - accuracy: 0.8806 - val_loss: 4.7498 - val_accuracy: 0.6818\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 8s 237ms/step - loss: 3.2235 - accuracy: 0.8433 - val_loss: 3.5878 - val_accuracy: 0.7727\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 8s 231ms/step - loss: 2.3578 - accuracy: 0.8731 - val_loss: 3.2360 - val_accuracy: 0.9545\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 2.4606 - accuracy: 0.8582 - val_loss: 17.3136 - val_accuracy: 0.5909\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 8s 226ms/step - loss: 9.4844 - accuracy: 0.7239 - val_loss: 6.8071 - val_accuracy: 0.7727\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 8s 234ms/step - loss: 5.1662 - accuracy: 0.7761 - val_loss: 7.3515 - val_accuracy: 0.7727\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 8s 221ms/step - loss: 21.5740 - accuracy: 0.6567 - val_loss: 10.5274 - val_accuracy: 0.6364\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 7s 215ms/step - loss: 7.2334 - accuracy: 0.7612 - val_loss: 4.0751 - val_accuracy: 0.7727\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 8s 223ms/step - loss: 5.5606 - accuracy: 0.7910 - val_loss: 3.7712 - val_accuracy: 0.8182\n"
     ]
    }
   ],
   "source": [
    "early_stopper = EarlyStopping(patience = 2, monitor = 'loss', min_delta = 0.01)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', )\n",
    "callbacks = [reduce_lr]\n",
    "history = model.fit(train_generator,validation_data = val_generator, batch_size = 8,  epochs = 20, callbacks = callbacks, verbose = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "### tensorflow lite interpreter za raspberry\n",
    "### nej shrani augmentatione da mamo za trenirat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-drink",
   "metadata": {},
   "source": [
    "## TensorFlow Lite Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "export_dir = 'models/saved_model/'\n",
    "lite_filepath = 'models/foo.tflite'\n",
    "\n",
    "def convert(model, export_dir = export_dir, lite_filepath = lite_filepath):\n",
    "    tf.saved_model.save(model, export_dir)\n",
    "    lite_filepath = 'models/foo.tflite'\n",
    "    tflite_model_file = pathlib.Path(lite_filepath)\n",
    "    tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "gorgeous-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models\n",
    "!chmod +x models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "difficult-technique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "convert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "## using the interpreter\n",
    "\n",
    "## to daš v raspberry\n",
    "\n",
    "interpreter = tf.lite.Interpreter(lite_filepath)\n",
    "signature = interpreter.get_signature_runner()\n",
    "output = signature(x = image)\n",
    "print(output['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.tensorflow.org/lite/guide/inference#load_and_run_a_model_in_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(data_folder + \"test.jpg\").convert('RGB').resize((width, height))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
